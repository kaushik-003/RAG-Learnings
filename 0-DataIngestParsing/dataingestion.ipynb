{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaushik003/Documents/projects/RAG/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup is completed!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "\n",
    "print(\"setup is completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Document structure in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document structure\n",
      "Content: This is a sample document for testing purposes.\n",
      "Metadata: {'source': 'sample_source', 'page': 1, 'author': 'Test Author', 'date_created': '2024-06-01'}\n"
     ]
    }
   ],
   "source": [
    "## create a simple doc\n",
    "doc = Document(\n",
    "    page_content=\"This is a sample document for testing purposes.\",\n",
    "    metadata={\n",
    "        \"source\": \"sample_source\",\n",
    "        \"page\": 1 ,\n",
    "        \"author\": \"Test Author\",\n",
    "        \"date_created\": \"2024-06-01\"\n",
    "        \n",
    "        }\n",
    ")\n",
    "\n",
    "print(\"Document structure\")\n",
    "print(f\"Content: {doc.page_content}\")\n",
    "print(f\"Metadata: {doc.metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Text files (.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a simple dir\n",
    "\n",
    "\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample text files created.\n"
     ]
    }
   ],
   "source": [
    "sample_texts ={\n",
    "    \"data/text_files/python_intro.txt\": \"\"\"Anyone can learn Python programming.\n",
    "Python is a versatile language used for web development, data analysis, artificial intelligence, and more.\n",
    "It has a simple syntax that makes it easy to read and write code.\n",
    "It has a large community and extensive libraries that support various applications.\n",
    "It is a great language for beginners and experienced developers alike.\"\"\",\n",
    "\n",
    "    \"data/text_files/machine_learning.txt\": \"\"\" Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from data.\n",
    "    It involves algorithms that improve their performance as they are exposed to more data over time.\n",
    "    Common machine learning tasks include classification, regression, clustering, and recommendation.\n",
    "    Machine learning is widely used in various applications such as image recognition, natural language processing, and predictive analytics.\n",
    "    Types of machine learning include supervised learning, unsupervised learning, and reinforcement learning.\"\"\",\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "for file_path, content in sample_texts.items():\n",
    "    with open(file_path, \"w\", encoding = \"utf-8\" ) as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\" Sample text files created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextLoader - Read single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s)\n",
      "content preview: Anyone can learn Python programming.\n",
      "Python is a versatile language used for web development, data a...\n",
      "metadata: {'source': 'data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "##Loading single text file\n",
    "\n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} document(s)\")\n",
    "print(f\"content preview: {documents[0].page_content[:100]}...\")\n",
    "print(f\"metadata: {documents[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Loader - Multiple Text files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2890.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 document(s) from directory 'data/text_files'\n",
      "\n",
      " Document 1:\n",
      " source : data/text_files/python_intro.txt\n",
      " Length : 364 characters\n",
      "\n",
      " Document 2:\n",
      " source : data/text_files/machine_learning.txt\n",
      " Length : 571 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# loading all text files from a directory\n",
    "\n",
    "dir_loader = DirectoryLoader(\"data/text_files\", \n",
    "                             glob=\"**/*.txt\", #pattern to match files\n",
    "                             loader_cls=TextLoader, #loader class to use \n",
    "                             loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "                             show_progress=True #show loading progress\n",
    "                             )\n",
    "\n",
    "docs = dir_loader.load()\n",
    "\n",
    "print(f\"Loaded {len (docs)} document(s) from directory 'data/text_files'\")\n",
    "for i, document in enumerate(docs):\n",
    "   print(f\"\\n Document {i+1}:\")\n",
    "   print(f\" source : {document.metadata['source']}\")\n",
    "   print(f\" Length : {len(document.page_content)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory loader characteristics :\n",
    "\n",
    "#### Adv:\n",
    "- loads multiple files at once\n",
    "- supports glob patterns\n",
    "- progressive tracking\n",
    "- Recursive directory scanning\n",
    "\n",
    "#### DisAdv:\n",
    "- All files must be of same type\n",
    "- Limited error handling per file\n",
    "- can be memory intensive for large directories\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Anyone can learn Python programming.\\nPython is a versatile language used for web development, data analysis, artificial intelligence, and more.\\nIt has a simple syntax that makes it easy to read and write code.\\nIt has a large community and extensive libraries that support various applications.\\nIt is a great language for beginners and experienced developers alike.')]\n"
     ]
    }
   ],
   "source": [
    "## Different text splitting strategies\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Charecter text splitting\n",
    "\n",
    "Character splitting means dividing your text into pieces based on a set number of characters, regardless of what the text says. It’s a simple way to start understanding splitting, but it’s not great for real use.\n",
    "\n",
    "Pros: Easy & Simple\n",
    "\n",
    "Cons: Doesn’t consider text structure well\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anyone can learn Python programming.\\nPython is a versatile language used for web development, data analysis, artificial intelligence, and more.\\nIt has a simple syntax that makes it easy to read and write code.\\nIt has a large community and extensive libraries that support various applications.\\nIt is a great language for beginners and experienced developers alike.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## charecter text splitter\n",
    "\n",
    "text = documents[0].page_content\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Text Splitter\n",
      "Created 3 chunks \n",
      "first chunk : Anyone can learn Python programming.\n",
      "Python is a versatile language used for web development, data a...\n"
     ]
    }
   ],
   "source": [
    "print(\"Character Text Splitter\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", # split by new lines\n",
    "    chunk_size=200, # max chunk size\n",
    "    chunk_overlap=20, # overlap between chunks\n",
    "    length_function=len # how to measure chunk size\n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Created {len(char_chunks)} chunks \")\n",
    "print(f\"first chunk : {char_chunks[0] [:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anyone can learn Python programming.\n",
      "Python is a versatile language used for web development, data analysis, artificial intelligence, and more.\n",
      "--------------------------------\n",
      "It has a simple syntax that makes it easy to read and write code.\n",
      "It has a large community and extensive libraries that support various applications.\n",
      "--------------------------------\n",
      "It is a great language for beginners and experienced developers alike.\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks[0])\n",
    "print(\"--------------------------------\")\n",
    "print(char_chunks[1])\n",
    "print(\"--------------------------------\")\n",
    "print(char_chunks[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Recursive charecter Text Splitter\n",
    "\n",
    "Character Splitting has a flaw, it doesn’t consider how our document is organized. We just split it by a set number of characters.\n",
    "\n",
    "The Recursive Character Text Splitter fixes this.\n",
    "We set specific marks to split our documents.\n",
    "“\\n\\n” — Paragraph breaks,        \n",
    "“\\n” — New lines, “ “ — Spaces “” — Individual characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Character Text Splitter\n",
      "Created 3 chunks \n",
      "first chunk : Anyone can learn Python programming.\n",
      "Python is a versatile language used for web development, data a...\n"
     ]
    }
   ],
   "source": [
    "# Recursive Character Text Splitter\n",
    "\n",
    "print(\"Recursive Character Text Splitter\")\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], # hierarchy of separators\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Created {len(recursive_chunks)} chunks \")\n",
    "print(f\"first chunk : {recursive_chunks[0] [:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anyone can learn Python programming.\n",
      "Python is a versatile language used for web development, data analysis, artificial intelligence, and more.\n",
      "--------------------------------\n",
      "It has a simple syntax that makes it easy to read and write code.\n",
      "It has a large community and extensive libraries that support various applications.\n",
      "--------------------------------\n",
      "It is a great language for beginners and experienced developers alike.\n"
     ]
    }
   ],
   "source": [
    "print(recursive_chunks[0])\n",
    "print(\"--------------------------------\")\n",
    "print(recursive_chunks[1])\n",
    "print(\"--------------------------------\")\n",
    "print(recursive_chunks[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "simple text example - 7 chunks : \n",
      "\n",
      "Chunk 1 : 'In this world of AI, we are witnessing rapid advancements in technology. we see' \n",
      "Chunk 2 : 'technology. we see AI being integrated into various industries, from healthcare' \n",
      "--------------------------------\n",
      "Chunk 2 : 'technology. we see AI being integrated into various industries, from healthcare' \n",
      "Chunk 3 : 'from healthcare to finance. The potential for AI to revolutionize the way we' \n",
      "--------------------------------\n",
      "Chunk 3 : 'from healthcare to finance. The potential for AI to revolutionize the way we' \n",
      "Chunk 4 : 'the way we live and work is immense. However, it also raises important ethical' \n",
      "--------------------------------\n",
      "Chunk 4 : 'the way we live and work is immense. However, it also raises important ethical' \n",
      "Chunk 5 : 'important ethical considerations that need to be addressed. As we continue to' \n",
      "--------------------------------\n",
      "Chunk 5 : 'important ethical considerations that need to be addressed. As we continue to' \n",
      "Chunk 6 : 'As we continue to develop AI technologies, it is crucial to ensure that they' \n",
      "--------------------------------\n",
      "Chunk 6 : 'As we continue to develop AI technologies, it is crucial to ensure that they' \n",
      "Chunk 7 : 'to ensure that they are used responsibly and for the benefit of all humanity.' \n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a split without natural breakpoints\n",
    "simple_text = \" In this world of AI, we are witnessing rapid advancements in technology. we see AI being integrated into various industries, from healthcare to finance. The potential for AI to revolutionize the way we live and work is immense. However, it also raises important ethical considerations that need to be addressed. As we continue to develop AI technologies, it is crucial to ensure that they are used responsibly and for the benefit of all humanity.\" \n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\" \"],\n",
    "    chunk_size=80,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(simple_text)\n",
    "\n",
    "print(f\"\\nsimple text example - {len(chunks)} chunks : \\n\")\n",
    "\n",
    "for i in range(len(chunks) -1):\n",
    "    print(f\"Chunk {i+1} : '{chunks[i]}' \")\n",
    "    print(f\"Chunk {i+2} : '{chunks[i+1]}' \")\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Token Text Splitter\n",
    "\n",
    "A Token Text Splitter is a specialized text splitting utility designed to divide large documents into smaller pieces, or chunks, where the size of those chunks is measured by the count of tokens, rather than the number of characters.\n",
    "\n",
    "This method is crucial for Large Language Model (LLM) applications, especially in Retrieval-Augmented Generation (RAG), because LLMs have a strict limit on the number of tokens they can process in their context window (4096 or 8192 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Text Splitter\n",
      "Created 2 chunks \n",
      "first chunk : Anyone can learn Python programming.\n",
      "Python is a versatile language used for web development, data a...\n"
     ]
    }
   ],
   "source": [
    "# Token Text Splitter\n",
    "print(\"Token Text Splitter\")\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50, # max tokens per chunk\n",
    "    chunk_overlap=10 # overlap between chunks\n",
    ")\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Created {len(token_chunks)} chunks \")\n",
    "print(f\"first chunk : {token_chunks[0] [:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anyone can learn Python programming.\n",
      "Python is a versatile language used for web development, data analysis, artificial intelligence, and more.\n",
      "It has a simple syntax that makes it easy to read and write code.\n",
      "It has a large community and extensive\n",
      "--------------------------------\n",
      " code.\n",
      "It has a large community and extensive libraries that support various applications.\n",
      "It is a great language for beginners and experienced developers alike.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(token_chunks[0])\n",
    "print(\"--------------------------------\")\n",
    "print(token_chunks[1])\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparison\n",
    "\n",
    "### Comparison of different text splitting strategies\n",
    "\n",
    "#### character text splitter:\n",
    "\"simple and effective for basic splitting tasks.\n",
    "good for structured text with clear delimiters.\n",
    "May break mid-sentence\n",
    "\n",
    "Use When : Simple text with clear delimiters\n",
    "\n",
    "#### Recursive Character Text Splitter:\n",
    "more sophisticated, respects natural text boundaries.\n",
    "better for complex or unstructured text.\n",
    "best general-purpose splitter\n",
    "Tries multiple separators in order\n",
    "slightly more complex than basic character splitter\n",
    "\n",
    "Use When : Default choice for most text splitting needs\n",
    "\n",
    "#### Token Text Splitter:\n",
    "Respects model token limits accurately.\n",
    "accurate for embedding and language model tasks.\n",
    "slower than character-based splitters due to tokenization step\n",
    "\n",
    "Use When : Working with token-limited models or embeddings\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

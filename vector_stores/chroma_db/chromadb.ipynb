{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d24416",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB. \n",
    "-> RAG is a powerful technique that combines the capabilities of LLMs with external retrieval.\n",
    "\n",
    "Langchain : framework for building and developing apps powered by language models  \n",
    "Chroma DB : opensource vector DB for storing and retrieving embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31928742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2513824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain imports\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "## vector store imports\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# utility imports\n",
    "from typing import List\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f402e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Retrieval-Augmented Generation (RAG) Architecture Overview:\n",
      "      1.Document Loading: Load documents from various sources (e.g., text files, PDFs, web pages).\n",
      "      2.Text Splitting: Split documents into smaller chunks for better processing.\n",
      "      3.Embedding Generation: Convert text chunks into vector embeddings using pre-trained models.\n",
      "      4. vector Store Creation: Store embeddings in a vector database for efficient retrieval.\n",
      "      5.Query Processing: Convert user queries into embeddings.\n",
      "      6.similarity Search: Retrieve relevant document chunks based on query embeddings.\n",
      "      7. context augmentation: Combine retrieved documents with the original query.\n",
      "      8. response Generation: Generate responses using a language model based on the augmented context.\n",
      "\n",
      "    Benefits of RAG:\n",
      "        - Enhanced Accuracy: Provides more accurate and contextually relevant responses.\n",
      "        - reduced Hallucination: Minimizes the chances of generating incorrect information.\n",
      "        - Up-to-date Information: Allows integration of the latest data without retraining the model.\n",
      "        - works with domain-specific knowledge: Tailors responses to specific fields or industries.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RAG ARCHITECTURE OVERVIEW\n",
    "\n",
    "print(\"\"\"\n",
    "    Retrieval-Augmented Generation (RAG) Architecture Overview:\n",
    "      1.Document Loading: Load documents from various sources (e.g., text files, PDFs, web pages).\n",
    "      2.Text Splitting: Split documents into smaller chunks for better processing.\n",
    "      3.Embedding Generation: Convert text chunks into vector embeddings using pre-trained models.\n",
    "      4. vector Store Creation: Store embeddings in a vector database for efficient retrieval.\n",
    "      5.Query Processing: Convert user queries into embeddings.\n",
    "      6.similarity Search: Retrieve relevant document chunks based on query embeddings.\n",
    "      7. context augmentation: Combine retrieved documents with the original query.\n",
    "      8. response Generation: Generate responses using a language model based on the augmented context.\n",
    "\n",
    "    Benefits of RAG:\n",
    "        - Enhanced Accuracy: Provides more accurate and contextually relevant responses.\n",
    "        - reduced Hallucination: Minimizes the chances of generating incorrect information.\n",
    "        - Up-to-date Information: Allows integration of the latest data without retraining the model.\n",
    "        - works with domain-specific knowledge: Tailors responses to specific fields or industries.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6836ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b96946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : /var/folders/0x/l0pl9q9552d_t68n7_dctx240000gn/T/tmprcro__xz\n"
     ]
    }
   ],
   "source": [
    "## store the smaple documents in text files\n",
    "\n",
    "import tempfile # to create a temporary directory\n",
    "temp_dir=tempfile.mkdtemp() # create a temporary directory\n",
    "\n",
    "for i,doc in enumerate(sample_docs): # iterate over sample documents\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f: # create and open a text file\n",
    "        f.write(doc) # write the document content to the file\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85d2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"doc_{i}.txt\",\"w\") as f: # create and open a text file\n",
    "        f.write(doc) # write the document content to the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27ecac2",
   "metadata": {},
   "source": [
    "### 2. DOCUMENT LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0078cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 3 documents.\n",
      "\n",
      " First document preview : \n",
      "\n",
      "    Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity r\n"
     ]
    }
   ],
   "source": [
    "## Document Loading\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load docs from the directory\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\", # directory path\n",
    "    glob=\"*.txt\", # load all text files\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\":\"utf-8\"}\n",
    ")\n",
    "\n",
    "documents = loader.load() # list of Document objects\n",
    "\n",
    "print(f\" Loaded {len(documents)} documents.\")\n",
    "print(\"\\n First document preview : \")\n",
    "print(documents[0].page_content[:200])  # print first 200 characters of the first document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314f0a1",
   "metadata": {},
   "source": [
    "### 3. DOCUMENT SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88dda1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total Chunks created : 5\n",
      "\n",
      " First chunk preview : \n",
      "content: Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NL...\n",
      "metadata: {'source': 'data/doc_2.txt'}\n"
     ]
    }
   ],
   "source": [
    "# intilalize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, # size of each chunk\n",
    "    chunk_overlap=50, # overlap between chunks\n",
    "    separators=[\" \", \"\"], # preferred separators\n",
    "    length_function=len # function to calculate length\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)  # split documents into chunks and store in chunks list\n",
    "\n",
    "print(f\" Total Chunks created : {len(chunks)}\")\n",
    "print(\"\\n First chunk preview : \")\n",
    "print(f\"content: {chunks[0].page_content[:150]}...\")  # print first 150 characters of the first chunk\n",
    "print(f\"metadata: {chunks[0].metadata}\")  # print metadata of the first chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d3aed",
   "metadata": {},
   "source": [
    "### 4. EMBEDDING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d28156",
   "metadata": {},
   "source": [
    "#### Initialise the ChromaDB vectore store and store the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79156df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a chromadb vector store\n",
    "\n",
    "persist_directory = \"./chroma_db\"  # directory to store the vector database\n",
    "\n",
    "## intializr chromadb with HuggingFace embeddings\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks, # list of document chunks\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"), # embedding model\n",
    "    persist_directory=persist_directory, # directory to store the vector database\n",
    "    collection_name=\"rag_docs\" # name of the collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cba2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector store created with 15 vectors.\n",
      "persisted at : ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "print(f\"vector store created with {vector_store._collection.count()} vectors.\")\n",
    "print(f\"persisted at : {persist_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e0e4",
   "metadata": {},
   "source": [
    "### Test similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "360e1553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the main types of machine learning?\"\n",
    "\n",
    "similar_docs = vector_store.similarity_search(\n",
    "    query=query, # user query\n",
    "    k=3 # number of similar documents to retrieve\n",
    ")\n",
    "\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4127585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  0.6450324058532715),\n",
       " (Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  0.6450324058532715),\n",
       " (Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       "  0.6450324058532715)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## advance similarity search with scores\n",
    "query = \"Explain the concept of deep learning.\"\n",
    "similar_docs_with_scores = vector_store.similarity_search_with_score(\n",
    "    query=query, # user query\n",
    "    k=3 # number of similar documents to retrieve\n",
    ")   \n",
    "similar_docs_with_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b508c9",
   "metadata": {},
   "source": [
    "### Initialize LLM,RAG chain, Prompt Template, Query to the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e573716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Now you don't even need to pass the api_key argument; it will find it automatically\n",
    "llm = ChatGroq(\n",
    "    model_name=\"openai/gpt-oss-120b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a3a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Reinforcement Learning (RL) in a nutshell**\\n\\nImagine you‚Äôre teaching a pet dog to fetch a ball. You don‚Äôt write the dog a step‚Äëby‚Äëstep manual; instead, you let the dog try things, and you give it treats (rewards) when it does something you like and ignore or gently correct it when it doesn‚Äôt. Over time, the dog learns which actions lead to treats and which don‚Äôt, and it gets better at fetching the ball quickly and correctly.\\n\\nReinforcement learning works the same way, just with a computer program (the **agent**) instead of a dog. Here are the key pieces, broken down into everyday language:\\n\\n| RL Piece | Everyday Analogy | What It Means in RL |\\n|----------|------------------|---------------------|\\n| **Agent** | The dog (or a kid, a robot, a video‚Äëgame character) | The decision‚Äëmaker that takes actions. |\\n| **Environment** | The backyard, the park, the room where the dog plays | Everything the agent interacts with; it reacts to the agent‚Äôs actions. |\\n| **State** | What the dog sees right now ‚Äì where the ball is, where the dog is, obstacles nearby | A snapshot of the situation that the agent can use to decide what to do. |\\n| **Action** | The dog‚Äôs possible moves ‚Äì run left, run right, pick up the ball, bark | Anything the agent can do in that state. |\\n| **Reward** | A tasty treat (or a scold) the dog gets after an action | A number that tells the agent ‚Äúthis was good (+1), bad (‚Äë1), or neutral (0).‚Äù |\\n| **Policy** | The dog‚Äôs habit: ‚ÄúIf I see the ball, run to it; if I‚Äôm near the owner, sit.‚Äù | The rule (often a table or a neural network) that maps states to actions. |\\n| **Goal** | Getting as many treats as possible in a play session | Maximizing the total reward over time (called **cumulative reward**). |\\n\\n---\\n\\n### How the learning loop works\\n\\n1. **Observe** ‚Äì The agent looks at the current state (e.g., ‚Äúball is 5 meters ahead, I‚Äôm at the door‚Äù).  \\n2. **Choose** ‚Äì It picks an action based on its current policy (maybe it runs forward).  \\n3. **Act** ‚Äì The action changes the environment (the dog moves, the ball‚Äôs distance changes).  \\n4. **Feedback** ‚Äì The environment gives a reward (the dog gets a treat if it gets closer to the ball).  \\n5. **Update** ‚Äì The agent tweaks its policy so that actions that got good rewards are more likely next time, and actions that got bad rewards are less likely.\\n\\nThis cycle repeats millions of times, and the agent gradually improves, just like the dog learns the best way to fetch the ball.\\n\\n---\\n\\n### Why ‚Äúreinforcement‚Äù and not just ‚Äúlearning‚Äù?\\n\\n- **Trial‚Äëand‚Äëerror**: The agent isn‚Äôt told the correct answer upfront. It discovers good behavior by trying things and seeing what works.\\n- **Delayed reward**: Sometimes the payoff comes later (e.g., a chess move that leads to a win many moves down the line). The agent must learn to credit earlier actions for later rewards.\\n- **Exploration vs. exploitation**: The agent must balance trying new actions (exploring) to discover better rewards, and using what it already knows works (exploiting). Think of the dog sometimes sniffing a new path just in case it leads to a hidden treat.\\n\\n---\\n\\n### A super‚Äësimple example\\n\\n**Problem**: A robot is in a hallway with three rooms: Left, Center, Right. Only the Right room has a charging station (reward = +10). The other rooms give nothing (reward = 0). The robot can move left or right each step.\\n\\n**Learning steps**:\\n\\n| Step | State (where robot is) | Action taken | Reward received | What robot learns |\\n|------|------------------------|--------------|----------------|-------------------|\\n| 1    | Center                 | Move right   | 0 (still not at charger) | ‚ÄúMoving right can be good, keep trying.‚Äù |\\n| 2    | Right (now)            | Stay (do nothing) | +10 (found charger) | ‚ÄúBeing in Right and staying gives big reward.‚Äù |\\n| 3    | Center                 | Move left    | 0 | ‚ÄúLeft isn‚Äôt rewarding now.‚Äù |\\n| ‚Ä¶    | ‚Ä¶                      | ‚Ä¶            | ‚Ä¶ | Over many repeats, the robot‚Äôs policy becomes ‚ÄúFrom Center, move right; from Right, stay.‚Äù |\\n\\nAfter enough loops, the robot reliably goes to the charger and stays there.\\n\\n---\\n\\n### Real‚Äëworld flavors of RL\\n\\n| Domain | What the ‚Äúagent‚Äù is | What the ‚Äúreward‚Äù looks like |\\n|--------|--------------------|------------------------------|\\n| Video games | Game AI (e.g., an NPC) | Score increase, level completion |\\n| Robotics | Physical robot arm | Energy saved, task finished, no collisions |\\n| Recommendation systems | Algorithm suggesting movies | Click‚Äëthroughs, watch time |\\n| Finance | Trading bot | Profit, risk‚Äëadjusted returns |\\n| Healthcare | Treatment planner | Patient health outcomes, side‚Äëeffect minimization |\\n\\n---\\n\\n### TL;DR (the ultra‚Äësimple version)\\n\\n- **Reinforcement learning** is a way for a computer program to learn how to act by trying things out, getting feedback (rewards), and gradually improving.\\n- It‚Äôs like teaching a pet with treats: the program discovers the best behavior on its own, rather than being given explicit instructions for every situation.\\n- The core loop is **observe ‚Üí act ‚Üí get reward ‚Üí update** and it repeats until the agent becomes good at maximizing its total reward.\\n\\nThat‚Äôs it! üéâ If you want to dig deeper, the next steps are learning about **value functions** (how good a state is) and **policy‚Äëgradient methods** (directly tweaking the policy), but the above captures the heart of reinforcement learning in plain language.', additional_kwargs={'reasoning_content': 'We need to explain RL simply. Use analogies, mention agent, environment, reward, trial-and-error, policy, etc. Keep simple.'}, response_metadata={'token_usage': {'completion_tokens': 1299, 'prompt_tokens': 81, 'total_tokens': 1380, 'completion_time': 2.87077817, 'completion_tokens_details': {'reasoning_tokens': 30}, 'prompt_time': 0.003669538, 'prompt_tokens_details': None, 'queue_time': 0.054829542, 'total_time': 2.874447708}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_4a19b1544c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b5efe-c169-7871-aa0c-bbb9364d4d5a-0', usage_metadata={'input_tokens': 81, 'output_tokens': 1299, 'total_tokens': 1380, 'output_token_details': {'reasoning': 30}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response = llm.invoke([\"Explain the concept of reinforcement learning in simple terms.\"])\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8537c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.base import init_chat_model # to initialize chat model\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    model_provider=\"groq\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a36bede7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Artificial Intelligence (AI)** is a branch of computer science that focuses on creating systems capable of performing tasks that normally require human intelligence. These tasks include learning, reasoning, problem‚Äësolving, perception, language understanding, and decision‚Äëmaking.\\n\\n### Core ideas\\n| Concept | What it means |\\n|---------|----------------|\\n| **Machine Learning (ML)** | Algorithms that improve their performance automatically through experience (e.g., recognizing images after being shown many examples). |\\n| **Deep Learning** | A subset of ML that uses multi‚Äëlayered neural networks to model complex patterns, especially effective for speech, vision, and language tasks. |\\n| **Natural Language Processing (NLP)** | Techniques for understanding, generating, and translating human language (e.g., chatbots, translators). |\\n| **Computer Vision** | Methods for interpreting visual data‚Äîidentifying objects, faces, scenes, etc. |\\n| **Reinforcement Learning** | Training agents to make sequences of decisions by rewarding desirable outcomes (e.g., game‚Äëplaying AIs). |\\n\\n### Types of AI (by capability)\\n| Category | Description |\\n|----------|-------------|\\n| **Narrow (or Weak) AI** | Designed for a specific task (e.g., recommendation engines, voice assistants). This is the form of AI that exists today. |\\n| **General (or Strong) AI** | Hypothetical systems that could understand, learn, and apply knowledge across any domain, similar to human intelligence. Not yet achieved. |\\n| **Superintelligent AI** | A speculative future AI that would surpass human intelligence in all areas. |\\n\\n### Common applications\\n- **Personal assistants** (Siri, Alexa, Google Assistant)  \\n- **Recommendation systems** (Netflix, Amazon)  \\n- **Autonomous vehicles** (self‚Äëdriving cars)  \\n- **Medical diagnostics** (image analysis, drug discovery)  \\n- **Finance** (fraud detection, algorithmic trading)  \\n- **Customer service** (chatbots, automated support)  \\n\\n### How AI works (high‚Äëlevel)\\n1. **Data collection** ‚Äì Gather large, relevant datasets.  \\n2. **Model building** ‚Äì Choose an algorithm (e.g., neural network, decision tree) and train it on the data.  \\n3. **Evaluation** ‚Äì Test the model on unseen data to measure accuracy, precision, recall, etc.  \\n4. **Deployment** ‚Äì Integrate the model into an application where it makes predictions or decisions.  \\n5. **Monitoring & updating** ‚Äì Continuously collect new data and retrain to maintain performance.\\n\\n### Ethical considerations\\n- **Bias & fairness:** AI can inherit biases present in training data.  \\n- **Privacy:** Handling personal data responsibly.  \\n- **Transparency:** Explaining how decisions are made (especially in high‚Äëstakes domains).  \\n- **Job impact:** Automation may shift labor markets.  \\n\\n### Quick takeaway\\nAI is about giving computers the ability to **learn from data** and **perform intelligent tasks** without explicit step‚Äëby‚Äëstep programming. While today‚Äôs AI excels at narrow, well‚Äëdefined problems, research continues toward broader, more adaptable intelligence.', additional_kwargs={'reasoning_content': 'The user asks \"what is AI\". Need to respond with an explanation. Follow guidelines: Provide concise, accurate definition. Possibly include brief history, types, applications. No disallowed content. Should be safe. Use neutral tone.'}, response_metadata={'token_usage': {'completion_tokens': 696, 'prompt_tokens': 74, 'total_tokens': 770, 'completion_time': 1.459197154, 'completion_tokens_details': {'reasoning_tokens': 47}, 'prompt_time': 0.00287056, 'prompt_tokens_details': None, 'queue_time': 0.05031891, 'total_time': 1.462067714}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a09bde29de', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b5efe-db0a-76a1-9e23-d0ac56b32a36-0', usage_metadata={'input_tokens': 74, 'output_tokens': 696, 'total_tokens': 770, 'output_token_details': {'reasoning': 47}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(\"what is AI\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c8a4e",
   "metadata": {},
   "source": [
    "### Modern RAG chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b52dcc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate  #to create chat prompt templates\n",
    "from langchain_classic.chains import create_retrieval_chain # to create retrieval chain \n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain # to create stuff documents chain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43654611",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert vector store to retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwarg = {\"k\":3} ## retrieve top 3 relevant chunks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6556a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create prompt template \n",
    "\n",
    "system_prompt = \"\"\" You are an assistant for question-answering tasks.\n",
    "Use the following peices of retrieved context to answer the question.\n",
    "If you dont know the answer, just say you dont know.\n",
    "Use three sentences maximum and keep it concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba03bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' You are an assistant for question-answering tasks.\\nUse the following peices of retrieved context to answer the question.\\nIf you dont know the answer, just say you dont know.\\nUse three sentences maximum and keep it concise.\\n\\nContext: {context}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afff5b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' You are an assistant for question-answering tasks.\\nUse the following peices of retrieved context to answer the question.\\nIf you dont know the answer, just say you dont know.\\nUse three sentences maximum and keep it concise.\\n\\nContext: {context}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x16e354550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x16e354f50>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create a document chain\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf22bb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x13f10a120>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=' You are an assistant for question-answering tasks.\\nUse the following peices of retrieved context to answer the question.\\nIf you dont know the answer, just say you dont know.\\nUse three sentences maximum and keep it concise.\\n\\nContext: {context}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x16e354550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x16e354f50>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create retrieval chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, doc_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8cda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\":\"Explain the three main types of machine learning.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49bf34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Explain the three main types of machine learning.',\n",
       " 'context': [Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')],\n",
       " 'answer': 'Supervised learning trains models on labeled data, allowing them to predict outcomes for new inputs. Unsupervised learning discovers patterns or structures in unlabeled data without predefined targets. Reinforcement learning trains agents to make sequential decisions by receiving rewards or penalties from their actions.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e3f4b",
   "metadata": {},
   "source": [
    "### Create RAG chain alternative - Using LCEL (langchain expression language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15e8e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f12debcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\" Use the following pieces of context to answer the question.\\nIf you don't have the answer, just say that you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer: \"), additional_kwargs={})])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create custom prompt\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\" Use the following pieces of context to answer the question.\n",
    "If you don't have the answer, just say that you don't know.\n",
    "Provide specific details from the context to support your answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "custom_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40eed757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x13f10a120>, search_kwargs={})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d790e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## format the output documents for the prompts\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b1422bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x13f10a120>, search_kwargs={})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\" Use the following pieces of context to answer the question.\\nIf you don't have the answer, just say that you don't know.\\nProvide specific details from the context to support your answer.\\n\\nContext: {context}\\n\\nQuestion: {question}\\n\\nAnswer: \"), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x16e354550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x16e354f50>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the chain using LCEL\n",
    "ragchain_lcel = (\n",
    "\n",
    "    {       \n",
    "        \"context\": retriever | format_docs, \n",
    "        \"question\": RunnablePassthrough()\n",
    "     }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "ragchain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8c61d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep Learning is a **subset of machine learning** that relies on **artificial neural networks**. These networks are modeled after the human brain and are built from multiple layers of interconnected nodes. By stacking many such layers, deep‚Äëlearning models can automatically learn hierarchical representations of data, which has driven breakthroughs in areas like computer vision, natural language processing, and speech recognition. The context explicitly defines deep learning this way:\\n\\n- ‚ÄúDeep learning is a subset of machine learning based on artificial neural networks.‚Äù  \\n- ‚ÄúThese networks are inspired by the human brain and consist of layers of interconnected nodes.‚Äù  \\n- ‚ÄúDeep learning has revolutionized fields like computer vision, natural language processing, and speech recognition.‚Äù'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = ragchain_lcel.invoke(\"what is Deep Learning?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3891d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Using LCEL approach\n",
    "\n",
    "def query_rag_lcel(question):\n",
    "    print(f\"Question: {question} \")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    #pass string directly to LCEL\n",
    "    answer = ragchain_lcel.invoke(question)\n",
    "    print(\"Answer:\", answer)\n",
    "\n",
    "    #Get source documents seperately if needed\n",
    "    docs = retriever.invoke(question)\n",
    "    print(\"\\n Source Documents:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n --- Source{i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "786be2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what are the key concepts in reinforcement learning? \n",
      "--------------------------------------------------\n",
      "Answer: The context describes reinforcement learning as being built around three core ideas:\n",
      "\n",
      "1. **Interaction with an environment** ‚Äì the learning system (the ‚Äúagent‚Äù) continuously engages with its surroundings, taking actions that affect the state of that environment.  \n",
      "2. **Rewards and penalties** ‚Äì the agent receives feedback in the form of positive rewards or negative penalties, which it uses to evaluate how good its actions were.  \n",
      "\n",
      "These two elements ‚Äì the ongoing **environment‚Äëagent interaction** and the **reward/penalty feedback** ‚Äì are presented as the fundamental concepts that define reinforcement learning. (The passage does not mention other concepts such as states, policies, or value functions.)\n",
      "\n",
      " Source Documents:\n",
      "\n",
      " --- Source1 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      " --- Source2 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      " --- Source3 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      " --- Source4 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n"
     ]
    }
   ],
   "source": [
    "query_rag_lcel(\"what are the key concepts in reinforcement learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fad5639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x13f10a120>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7667274",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding new docs to existing vector store\n",
    "\n",
    "new_document = \"\"\"\n",
    "Reinforcement Learning in Detail\n",
    "\n",
    "Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions\n",
    "by interacting with an environment. The agent receives rewards or penalties based on its actions,\n",
    "and its goal is to maximize the cumulative reward over time. Key concepts in RL include : states,\n",
    "actions, rewards, policies, and value functions. Popular RL algorithms include Q-learning, SARSA,\n",
    "and Deep Q-Networks (DQNs). RL has applications in robotics, game playing, and autonomous systems.\n",
    "RL has been successfully applied to gameplaying (like AlphGo), robotics, and autonomous systems.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ee49ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make decisions\\nby interacting with an environment. The agent receives rewards or penalties based on its actions,\\nand its goal is to maximize the cumulative reward over time. Key concepts in RL include : states,\\nactions, rewards, policies, and value functions. Popular RL algorithms include Q-learning, SARSA,\\nand Deep Q-Networks (DQNs). RL has applications in robotics, game playing, and autonomous systems.\\nRL has been successfully applied to gameplaying (like AlphGo), robotics, and autonomous systems.\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a01c266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = Document(\n",
    "    page_content= new_document,\n",
    "    metadata={\"source\": \"manual_addition\", \"topic\": \"Reinforcement Learning\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc97e197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual_addition', 'topic': 'Reinforcement Learning'}, page_content='\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make decisions\\nby interacting with an environment. The agent receives rewards or penalties based on its actions,\\nand its goal is to maximize the cumulative reward over time. Key concepts in RL include : states,\\nactions, rewards, policies, and value functions. Popular RL algorithms include Q-learning, SARSA,\\nand Deep Q-Networks (DQNs). RL has applications in robotics, game playing, and autonomous systems.\\nRL has been successfully applied to gameplaying (like AlphGo), robotics, and autonomous systems.\\n')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cc35cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual_addition', 'topic': 'Reinforcement Learning'}, page_content='Reinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make decisions\\nby interacting with an environment. The agent receives rewards or penalties based on its actions,\\nand its goal is to maximize the cumulative reward over time. Key concepts in RL include : states,\\nactions, rewards, policies, and value functions. Popular RL algorithms include Q-learning, SARSA,\\nand Deep Q-Networks (DQNs). RL has applications in robotics, game'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'Reinforcement Learning'}, page_content='(DQNs). RL has applications in robotics, game playing, and autonomous systems.\\nRL has been successfully applied to gameplaying (like AlphGo), robotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the document\n",
    "new_chunks = text_splitter.split_documents([new_doc])\n",
    "new_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ce5f8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['921ca94e-eb03-4f97-891a-5dccda3c02fa',\n",
       " 'd669b977-ffcf-48a7-b4f9-7a27e9f3350f']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add new docs to vector store\n",
    "vector_store.add_documents(new_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "104e8288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 2 chunks to vector store\n",
      "Total vectors now are : 17\n"
     ]
    }
   ],
   "source": [
    "print(f\"added {len(new_chunks)} chunks to vector store\")\n",
    "print(f\"Total vectors now are : {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a786d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what are key concepts in Reinforcement Learning? \n",
      "--------------------------------------------------\n",
      "Answer: The context highlights the core ideas that define reinforcement learning:\n",
      "\n",
      "- **Interaction with an environment** ‚Äì the learning agent must act within, and receive feedback from, a surrounding environment.  \n",
      "- **Rewards and penalties** ‚Äì the agent‚Äôs behavior is guided by receiving positive rewards for desirable actions and penalties (negative rewards) for undesirable ones.  \n",
      "\n",
      "These two elements‚Äîenvironmental interaction and the reward/penalty feedback loop‚Äîare presented in the text as the fundamental concepts of reinforcement learning.\n",
      "\n",
      " Source Documents:\n",
      "\n",
      " --- Source1 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      " --- Source2 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      " --- Source3 ---\n",
      "data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and penalties....\n",
      "\n",
      " --- Source4 ---\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are...\n"
     ]
    }
   ],
   "source": [
    "new_question = \"what are key concepts in Reinforcement Learning?\"\n",
    "\n",
    "result = query_rag_lcel(new_question)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c788dce",
   "metadata": {},
   "source": [
    "### Adv RAG Technique(Conversational Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf6c4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25f391bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a prompt that includes chat history\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and a latest user question,\n",
    "which might reference context from the chat history, formulate a standalone question\n",
    "which can be understood without the chat history. Do NOT answer the question.,\n",
    "just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7e2e788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x13f10a120>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1093ebc40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and a latest user question,\\nwhich might reference context from the chat history, formulate a standalone question\\nwhich can be understood without the chat history. Do NOT answer the question.,\\njust reformulate it if needed and otherwise return it as is.\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x16e354550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x16e354f50>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x13f10a120>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create history aware retriever\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "   llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe63c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational RAG chain created!!!\n"
     ]
    }
   ],
   "source": [
    "## create a new document chain with history\n",
    "\n",
    "qa_system_prompt = \"\"\"You are a helpful assistant that answers questions.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't have the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "\n",
    "# create a conversational Rag chain\n",
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriever,\n",
    "    question_answer_chain\n",
    ")\n",
    "\n",
    "print(\"Conversational RAG chain created!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d62eb35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: what is machine learning?\n",
      "A:  Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It uses data‚Äîoften labeled for supervised learning or unlabeled for unsupervised learning‚Äîto automatically discover patterns and make predictions. Reinforcement learning is another approach where models learn by interacting with an environment and receiving feedback.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "#First Question\n",
    "result_1 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"what is machine learning?\"\n",
    "})\n",
    "\n",
    "print(\"Q: what is machine learning?\")\n",
    "print(\"A: \", result_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e20c6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend([\n",
    "    HumanMessage(content=\"what is machine learning?\"),\n",
    "    AIMessage(content=result_1[\"answer\"])\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "34da0de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='what is machine learning?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It uses data‚Äîoften labeled for supervised learning or unlabeled for unsupervised learning‚Äîto automatically discover patterns and make predictions. Reinforcement learning is another approach where models learn by interacting with an environment and receiving feedback.', additional_kwargs={}, response_metadata={})],\n",
       " 'input': 'what are its main types?',\n",
       " 'context': [Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'data/doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')],\n",
       " 'answer': 'The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning trains models on labeled data, unsupervised learning discovers patterns in unlabeled data, and reinforcement learning learns by interacting with an environment and receiving feedback.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## follow up question\n",
    "\n",
    "result_2 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"what are its main types?\"\n",
    "})\n",
    "\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a5d72b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning trains models on labeled data, unsupervised learning discovers patterns in unlabeled data, and reinforcement learning learns by interacting with an environment and receiving feedback.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50900308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Store chat history\n",
    "chat_history = []\n",
    "\n",
    "# Contextualize: Rewrite question using history\n",
    "def contextualize_question(input_dict):\n",
    "    if not input_dict[\"chat_history\"]:\n",
    "        return input_dict[\"question\"]\n",
    "    \n",
    "    # Use LLM to rewrite question\n",
    "    msgs = [\n",
    "        (\"system\", \"Rewrite the question to be standalone using the chat history.\"),\n",
    "        *[(msg.type, msg.content) for msg in input_dict[\"chat_history\"]],\n",
    "        (\"human\", input_dict[\"question\"])\n",
    "    ]\n",
    "    rewritten = llm.invoke(msgs)\n",
    "    return rewritten.content\n",
    "\n",
    "# LCEL Chain with History\n",
    "conversational_chain = (\n",
    "    {\n",
    "        \"context\": RunnableLambda(contextualize_question) | retriever | format_docs,\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"]\n",
    "    }\n",
    "    | qa_prompt   # prompt that includes chat_history placeholder\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Usage\n",
    "response = conversational_chain.invoke({\n",
    "    \"question\": \"What is deep learning?\",\n",
    "    \"chat_history\": chat_history\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
